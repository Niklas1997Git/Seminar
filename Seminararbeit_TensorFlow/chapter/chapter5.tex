\chapter{Praktisches Beispiel}
\label{chap:praktischesBeispiel}
\section{Zielsetzung}
\label{sec:zielsetzung}
\printsubchapterauthor{\authorMarco}
Zur Darstellung eines Netzes, welches mithilfe von TensorFlow erstellt und trainiert wurde, soll im Zuge dieser Arbeit einen Demonstrator entwickelt werden. Das gewählte Beispiel ist die Erkennung von handgeschriebenen Ziffern. Dabei sollen vor allem die Effekte unterschiedlicher Lernraten auf die Richtigkeit der Vorhersagen untersucht werden.

Weiterhin wird auf die Nutzung des Brechnungsgraphen eingegangen und aufgezeigt, wie dieser im Demonstrator funktioniert. Dies betrifft ebenfalls die eingesetzten Operatoren und die Transformation der Tensoren.

Im Anschluss wird auf Probleme eingegangen, welche beim Erstellen und Trainieren des Netzes aufgetreten sind.

\section{Planung}
\label{sec:planung}
\printsubchapterauthor{\authorNiklas}
1 Seite

\section{Datensätze}
\label{sec:datensaetze}
\printsubchapterauthor{\authorMarco}
Der Datensatz, der zum Trainieren und Überprüfen des Netzes genutzt wurde, ist der MNIST Datensatz. Dieser Datensatz wurde von dem National Institute of Standards and Technology angefertigt und besteht aus 60.000 Trainingsziffern und 10.000 Testziffern. Alle Zahlen sind handgeschrieben und auf eine Größe von 28x28 Pixeln verkleinert. Die einzelnen Ziffern weisen verschiedene Graustufen in ihrer Darstellung auf.

\section{Erstellen des Netzes}
\label{sec:erstellenDesNetzes}
\printsubchapterauthor{\authorNiklas}
Der Datensatz, der für das neuronale Netz genutzt wird besteht aus Bildern mit einer Größe von 28x28 Pixeln. Da dem neuronalen Netz jedes Pixel übergeben werden soll, muss zuerst die Länge des Eingangsarrays berechnet werden.
\begin{center} 28 * 28 = 784\end{center}
Das Eingangsarray besitzt eine Länge von 784 Einträgen. Daher muss die Eingabeschicht des neuronalen Netzes ebenfalls 784 Platzhalter besitzen, die diese Werte entgegennehmen. Da es sich bei den handgeschriebenen Zahlen nur um die Zahlen von 0 bis 9, also 10 Zahlen, handelt, benötigt das neuronale Netz eine Ausgangsschicht mit 10 Tensoren. Zur Anpassung der Gewichte wird im Training die Softmax-Regression oder auch logistische Regression verwendet. Nach dem Trainieren wird zu jeder Zahl ein Thumbnail angezeigt, das darstellt, welcher Pixelbereich ungefähr gesetzt sein muss, damit das neuronale Netz diese Zahl in dem Bild interpretiert.

\section{Auswertung}
\label{sec:auswertung}
\printsubchapterauthor{\authorMarco}
Das Netz wurde nach dem Erstellen mit verschiedenen Lernraten trainiert und validiert. Dabei wurden immer 10.000 Iterationen durchlaufen. Die untersuchten Lernraten lagen zwischen 0,0001 und 1. Für kleine Lernraten unter 0,01 war die Genauigkeit gering. Sie lag bei zwischen 75\% und 90\%. Lernraten zwischen 0,05 und 0,2 erreichten Genauigkeiten, die leicht über 90\% lagen. Die höchste Genauigkeit wurde mit einer Lernrate von 0,05 erzielt. Die erreichte  Genauigkeit lag bei 90,56\%.

\section{Probleme}
\label{sec:probleme}
\printsubchapterauthor{\authorNiklas}
Bei der Erstellung des neuronalen Netzes selbst sind keine großen Problem aufgetreten. Die einzigen Probleme, die auftraten fanden bei der Installation statt. Die einfachste Variante der Installation ist über eine virtuelle Umgebung von Anaconda. In dieser virtuellen Umgebung kann TensorFlow installiert werden, ohne die Python-Installation des Rechners zu verändern. Auf einem Mac ist ein relativ neues Betriebssystem nötig, um TensorFlow nutzen zu können. Das Betriesbssystem \textit{El Capitan} reicht dafür nicht aus. Auf einem Ubuntu 18.04 Rechner müssen nach abgeschlossener Installation manche Bibliotheken einzeln installiert werden. Auf einem Windows-Computer werden alle nötigen Bibliotheken bei der Installation mit installiert und TensorFlow ist nach der Installation einsatzbereit.