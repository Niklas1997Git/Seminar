\chapter{Arbeitsweise}
\label{chap:arbeitsweise}
%1.Unterkapitel
\section{Tensoren}
\label{sec:tensoren}
\printsubchapterauthor{\authorNiklas}
Insgesamt 1-2 Seiten

\subsection{Mathematische Definition}
\label{sec:mathematischeDefinition}
Bild 5.9 Deep-Learning Seite 136
Ein Tensor ist eine Bezeichnung für ein n-dimensionales Feld. In der Abbildung sind unterschiedliche Dimensionen von Feldern dargestellt. "Beispielsweise ist ein 1-x-1-Tensor ein Skalar, ein 1-x-n-Tensor ein Vektor, ein n-x-n-Tensor eine Matrix, und ein n-x-n-x-n-Tensor ist einfach ein dreidimensionales Feld"\citep{Einfuehrung}.

\subsection{Tensoren in TensorFlow}
\label{sec:tensorenInTensorflow}
In TensorFlow hingegen werden die Daten, die durch den Graphen fließen Tensoren genannt. Da diese Daten wie die Tensoren in der Mathematik verschiedene Dimensionen annehmen können, wie zum Beispiel einfache Zahlenwerte oder dreidimensionale Felder eines Bildes, basiert der Begriff auf dem mathematischen Begriff. \\

Tensoren besitzen in TensorFlow die Attribute Name, Shape und Datentyp. Diese Attribute können bei der Initialisierung gesetzt werden oder sie werden von TensorFlow automatisch hinzugefügt. TensorFlow unterstützt sehr viele Datentypen. Diese sind in der Tabelle Seite 33 zu sehen. Bei der Verwendung von unterschiedlichen Datentypen ist es wichtig eine Typcast zu verwenden, da sonst eine Ausnahme geworfen wird. Das Attribute Shape gibt an, ob es sich bei diesem Tensor um eine Skalar, einen Vektor, eine Matrix oder ein mehrdimensionales Feld handelt. Wenn das Shape-Attribut zum Beispiel die Werte (2, 3) besitzt, kann es für die Matrix $\mathit{[[1, 2, 3], [4, 5, 6]]}$ stehen, da diese aus zwei Zeilen und 3 Spalten besteht.\\
Da die Eingabeschicht eines Neuronalen Netzes die Eingabedaten anders verarbeitet als die inneren Schichten, besitzt TensorFlow drei unterschiedliche Arten von Tensoren. Für die Eingabeschicht werden die sogenannten Platzhalter genutzt. Bei der Initialisierung muss nur der Datentyp übergeben werden. Die Daten werden bei der Ausführung einer Session über ein "feed-Dictionary"  an die Eingabeschicht übergeben. In den inneren Schichten werden meistens Variablen verwendet, da es möglich sein muss, die Gewichte nach einem Durchlauf korrigieren zu können. Zur Initialisierung der Variablen muss ein Startwert angegeben werden. Außerdem ist es möglich Konstanten zu verwenden, jedoch werde diese oft nur in einfachen Berechnungen verwendet, da deren Werte nicht verändert werden können.
Bei der Ausführung einer Operation entstehen ebenfalls Objekte von Tensoren, deshalb müssen Operationen einer Variablen zugeordnet werden. Hier ist mit einer Variablen jedoch nicht das gleiche gemeint, wie im Vorherigen beschrieben sondern nur eine einfache Zuordnung. In dem folgendem Beispiel entsteht aus der Addition der beiden Konstanten a und b eine neue Variable c.\\
\begin{math}
a = tf.constant(5)\\ b = tf.constant(4)\\ c = tf.add(a, b)    
\end{math}

Tensor-Objekte entstehen bei der Ausführung einer Operation.



%2.Unterkapitel
\section{Operationen}
\label{sec:operationen}
\printsubchapterauthor{\authorMarco}
Ziele der Arbeit

\subsection{Typen}
\label{sec:typen}
Was ist die Motivation hinter dieser Arbeit

\subsection{Beispiele}
\label{sec:beispiele}
Was ist die Motivation hinter dieser Arbeit

%3.Unterkapitel
\section{Graphen}
\label{sec:graphen}
\printsubchapterauthor{\authorNiklas}
Insgesamt 3 Seiten

\subsection{Aufbau}
\label{sec:graphenAufbau}

Wie schon in Kapitel \ref{sec:allgemeines} erwähnt wurde, arbeitet TensorFlow auf einem Datenflussgraphen. Dabei handelt es sich um ein gerichtetes Diagramm, das ein mathematisches Problem darstellt. Diese Datenflussgraphen bestehen aus Tensoren \ref{sec:tensoren} und Operationen \ref{sec:operationen}, die miteinander verbunden sind. Durch eine Aneinanderreihung von unterschiedlichen Operationen, mit den dazugehörigen Tensoren als Werte, entsteht ein Datenflussgraph. Dieser wird als mathematische Grundlage für das Neuronale Netz genutzt.

\subsection{Funktionsweise}
\label{sec:graphenFunktionsweise}
Hier Bild 5.11 aus dem Buch Deep-Learning einfügen.\\
Die Abbildung zeigt eine einfache Berechnung als Datenflussgraphen, um den Ablauf zu verdeutlichen. Die Berechnung eines Graphen kann nur in einem \textit{tf.Session()}-Block ausgeführt werden. Am Anfang dieses Blocks wird zusätzlich eine \textit{tf.Session()} Variable angelegt. Dies wird durch den Ausdruck \textit{with tf.Session() as sess} realisiert. Das \textit{Session()}-Objekt wird später benötigt, um diese zu starten. Bevor die \textit{Session} gestartet wird, werden die Konstanten, oder auch Tensoren, a, b, c und d erstellt und ein Wert zugewiesen. Die letzte Operation wurde dem Tensor \textit{result} in der Form \textit{result = tf.sqrt(x3, "Wurzel")} zugewiesen. Für den Start muss der Operation der Tensor übergeben werden, der berechnet werden soll. Diese Operation muss zusätzlich einer Variablen übergeben werden, damit der Wert weiter verwendet werden kann. In diesem Fall sieht die Funktion wie folgt aus: \textit{res = sess.run(result)}. Über die Variable \textit{res} kann nun das Ergebnis ausgegeben werden.

Hier Bild 3-4 aus Buch EInfuehrung einfügen
Vor der Ausführung eines \textit{Session}-Blocks enthalten die wird durch das Aufrufen einer Operation nur eine Instanz dieses Objekts erstellt. Dieses Objekt enthält nur Referenz der Daten und noch keine richtigen Daten. Dies ändert sich mit dem Start der Ausführung und dem Durchlaufen der Operationen. Wie in der Abbildung zu sehen ist werden die Referenzen der Tensor-Objekte in A durch Tensor-Objekt-Instanzen ersetzt.

\subsection{Darstellung von Operationen}
\label{sec:darstellungOperationen}
Im Kapitel \ref{sec:operationen} wurde im Allgemeinen auf die Operationen in TensorFlow eingegangen. Dies wird nun noch für die Darstellung vertieft. 

\subsection{Vor- und Nachteile von Graphen zur Berechnung}
\label{sec:vorUndNachteile}
Durch die Verwendung von Graphen ist es möglich einzelne Operationen ohne große Umstände auszutauschen.


%4.Unterkapitel
\section{Trainieren des Netzes}
\label{sec:trainierenDesNetzes}
\printsubchapterauthor{\authorNiklas}
Insgesamt 1-2 Seiten


\subsection{Eingaben}
\label{sec:eingaben}
Für das Trainieren eines Neuronales Netzes werden, wie auch bei anderen Frameworks Trainingsdaten benötigt.\\
Platzhalter werden für die Eingaben verwendet.\\
Menge an Eingabedaten, wie es auch Platzhalter in der ersten Schicht gibt.\\
Aufteilen der Daten in Trainings- und Testdaten zur Überprüfung des Modells\\

\subsection{Ablauf}
\label{sec:ablauf}
Starten der Session\\
Initialisierung der Gewichte und Zuweisung der Daten oder Tensor-Objekte der Platzhalter\\
Anwendung eines Trainierungsverfahrens, wie Backpropagation\\
Durchlaufen der angegebenen Trainingsepochen\\

\subsection{Ergebnis}
\label{sec:ergebnis}
Nach Abschluss des Trainings ist ein trainiertes Neuronales Netz vorhanden\\